{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: научиться находить в тексте лексически/стилистически неправильные сочетания (коллокации) и предлагать более правильные замены.\n",
    "\n",
    "Решение: задача была разделена на подзадачи - 1) поиск неправильных сочетаний и 2) поиск возможных замен по эталонному списку, который был взят из корпуса русских академических текстов (корпус тоже делали мы). Поскольку большинство ошибок встречаются в именных и глагольных словосочетаниях, работать будем только с ними. \n",
    "\n",
    "Эталонные списки делаются из списков коллокаций корпуса, которые тоже делала я. Код можно посмотреть тут: https://github.com/MariaFjodorowa/catandthekittens/blob/develop/collocation_frequences/collocations%202_1.ipynb, готовые списки здесь: https://drive.google.com/drive/folders/1k_N-DZ-nLL5ro66-LxIaE4-dRwirdwZh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from natasha import NamesExtractor, AddressExtractor, DatesExtractor\n",
    "import pymorphy2\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz', binary=False)\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "domain_model=joblib.load('domain_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас я использую модель из русвекторес, для работы с которой надо, во-первых, лемматизировать слова, во-вторых, прилеплять к ним теги. На самом деле у нашего проекта есть свои собственные вордтувеки, посчитанные на корпусе киберленинки, для которых не надо преобразовывать слова и которые нельзя заставить работать у меня на виртуальной машине (зато они прекрасно функционируют у моих коллег)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_pm(word, tag):\n",
    "    if tag=='S':\n",
    "        return morph.parse(word)[0].normal_form+'_'+'NOUN'\n",
    "    elif tag=='V':\n",
    "        return morph.parse(word)[0].normal_form+'_'+'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    p=str(morph.parse(word)[0].tag).split(\",\")[0]\n",
    "    if p=='NOUN':\n",
    "        return 'S'\n",
    "    elif p=='VERB':\n",
    "        return 'V'\n",
    "    else:\n",
    "        return 'X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от того, к какому домену относится текст, выбираем эталонный список коллокаций для сравнения. Для определения домена используется SVM, предобученная на шестиграммах из каждого домена (по 100000 на домен). Код этой модели также могу показать, но там ничего особенного. F-мера модели - 94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def domain(string):\n",
    "    domain=domain_model.predict(list(string))[0]\n",
    "    if domain=='hist':\n",
    "        df=pd.read_csv('suggestions_hist.csv')\n",
    "        return df\n",
    "    elif domain=='ling':\n",
    "        df=pd.read_csv('suggestions.csv')\n",
    "        return df\n",
    "    elif domain=='law':\n",
    "        df=pd.read_csv('suggestions_law.csv')\n",
    "        return df\n",
    "    elif domain=='pol':\n",
    "        df=pd.read_csv('suggestions_pol.csv')\n",
    "        return df\n",
    "    elif domain=='psy':\n",
    "        df=pd.read_csv('suggestions_psy.csv')\n",
    "        return df\n",
    "    elif domain=='ec':\n",
    "        df=pd.read_csv('suggestions_ec.csv')\n",
    "        return df\n",
    "    elif domain=='soc':\n",
    "        df=pd.read_csv('suggestions_soc.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала в тексте находятся коллокации, которые подходят нам по тегам и которых нет в эталонном списке. Попытки изобрести более совершенный способ искать ошибки предпринимались, но успешны не были, поэтому пока что применяется словарный способ. Имена собственные и подобные слова исключаются из поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(text, collocations):\n",
    "    first=list(collocations.first_word)\n",
    "    second=list(collocations.second_word)\n",
    "    candidates={}\n",
    "    extractors = [NamesExtractor(), AddressExtractor(), DatesExtractor()]\n",
    "    personal=[]\n",
    "    for extractor in extractors:\n",
    "        matches = extractor(text)\n",
    "        for match in matches:\n",
    "            start, stop = match.span\n",
    "            for i in re.findall('\\w+', text[start:stop]):\n",
    "                personal.append(i.lower())\n",
    "    string=re.findall('[а-яА-ЯЁё]+', text.lower())\n",
    "    bigrams=list(nltk.bigrams(string))\n",
    "    for bigram in bigrams:\n",
    "        w1,w2=bigram[0], bigram[1]\n",
    "        if w1 not in personal and w2 not in personal:\n",
    "            tag1=tag(w1)\n",
    "            tag2=tag(w2)\n",
    "            if (tag1=='S' or tag1=='V') and (tag2=='S' or tag2=='V'):\n",
    "                if w1 in first or w2 in second:\n",
    "                    if w1 in first and w2 in second:\n",
    "                        indices1 = [i for i, x in enumerate(first) if x == w1]\n",
    "                        indices2 = [i for i, x in enumerate(second) if x == w2]\n",
    "                        if not set(indices1).isdisjoint(indices2):\n",
    "                            pass\n",
    "                        else:\n",
    "                            candidates['{} {}'.format(w1, w2)]='{} {}'.format(tag1, tag2)\n",
    "                    else:\n",
    "                        candidates['{} {}'.format(w1, w2)]='{} {}'.format(tag1, tag2)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кандидаты на замену подбираются по эталонному списку. Вес кандидата определяется, исходя из:  \n",
    "1) PMI между правильным словом и словом на замену (посчитан заранее и отмечен в списках);  \n",
    "2) схожести, вычисленной при помощи вордтувека;  \n",
    "3) близости слов в коллокационном кластере. Эта метрика вычисляется, если оба слова есть в эталонном списке по отдельности, но не вместе. Допустим, есть пара слов N и V, у которых в эталонном списке есть следующие коллокаты: N(V11, V12, V13), V(N11, N12, N13). У данных коллокатов есть свои пары V11(N21, N22), V12(N23, N24) и т.д. Мера близости N и V по кластеру - это количество таких слов N21, N22,..., которые совпадают с коллокатами V(N11, N12, N13), и таких слов V21, V22,..., которые совпадают с коллокатами N(V11, V12, V13);  \n",
    "4) схожести тегов заменяемого слова и замены.  \n",
    "\n",
    "Подробнее об этом алгоритме: https://aclanthology.info/pdf/W/W09/W09-2107.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suggest(candidates, collocations):\n",
    "    c_max=max(collocations.pmi)\n",
    "    corrections={}\n",
    "    for item in candidates.items():\n",
    "        suggestions={}\n",
    "        w1=item[0].split()[0]\n",
    "        w2=item[0].split()[1]\n",
    "        tag1=item[1].split()[0]\n",
    "        tag2=item[1].split()[1]\n",
    "        w1_sub=[]\n",
    "        w2_sub=[]\n",
    "        for i in range(len(collocations)-1):\n",
    "            #assuming that second word is wrong\n",
    "            if collocations.first_word[i]==w1 and collocations.second_tag[i]==tag2:\n",
    "                suggestions[w1+ ' ' +collocations.second_word[i]]=collocations.pmi[i]/c_max\n",
    "                try:\n",
    "                    suggestions[collocations.first_word[i]+ ' ' +w2]+=model.similarity(convert_pm(w1, tag1), convert_pm(collocations.second_word[i], tag2))\n",
    "                except:\n",
    "                    pass\n",
    "                if str(morph.parse(w2)[0].tag)==str(morph.parse(collocations.second_word[i])[0].tag):\n",
    "                    suggestions[w1+ ' ' +collocations.second_word[i]]+=0.1\n",
    "                w2_sub.append(collocations.second_word[i])\n",
    "            #assuming that first word is wrong\n",
    "            if collocations.second_word[i]==w2 and collocations.first_tag[i]==tag1:\n",
    "                suggestions[collocations.first_word[i]+ ' ' +w2]=collocations.pmi[i]/c_max\n",
    "                try:\n",
    "                    suggestions[collocations.first_word[i]+ ' ' +w2]+=model.similarity(convert_pm(collocations.first_word[i],tag1), convert_pm(w2,tag2))\n",
    "                except:\n",
    "                    pass\n",
    "                if str(morph.parse(w1)[0].tag)==str(morph.parse(collocations.first_word[i])[0].tag):\n",
    "                    suggestions[collocations.first_word[i]+ ' ' +w2]+=0.1\n",
    "                w1_sub.append(collocations.first_word[i])\n",
    "        #collocation cluster if both words could be substituted\n",
    "        if w1_sub and w2_sub:\n",
    "            for w in w1_sub:\n",
    "                for j in range(len(collocations)-1):\n",
    "                    if collocations.first_word[j]==w and collocations.second_word[j] in w2_sub:\n",
    "                        suggestions[w+' '+w2]+=1.0/len(w2_sub)\n",
    "            for k in w2_sub:\n",
    "                for j in range(len(collocations)-1):\n",
    "                    if collocations.second_word[j]==k and collocations.first_word[j] in w1_sub:\n",
    "                        suggestions[w1+' '+k]+=1.0/len(w1_sub)\n",
    "        variants=[]\n",
    "        for i in sorted(suggestions.items(), key=lambda x: x[-1], reverse=True):\n",
    "            if i[1]>=0.5:\n",
    "                variants.append(i)\n",
    "        corrections[item[0]]=variants[:10]\n",
    "    return corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем несколько строчек.  \n",
    "Первая строка: спорное сочетание - \"разрешение вопроса\";  \n",
    "Вторая строка: правильная (не берём в рассчёт пунктуацию :);  \n",
    "Третья строка: неправильное сочетание - \"автор думает\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1='цель работы - разрешение вопроса об использовании такого подхода в исследованиях'\n",
    "\n",
    "text2='результаты показанные на данном примере'\n",
    "\n",
    "text3='автор думает, что данный пример продемонстрировал'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь, кроме спорного сочетания, выловлено сочетание, являющееся правильным, что выявляет необходимость доработки системы отбора кандидатов - в частности, добавление элементов, которые бы не позволили захватывать слова на границах именных и глагольных групп (например, \"работы разрешение\" в данном случае). Коллокации, предлагаемые на замену таких выхваченных групп, бывают немного странными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stee/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'работы разрешение': [('работы снегурочкой', 0.6445432209029189),\n",
       "  ('работы упрощение', 0.6445432209029189),\n",
       "  ('работы механизмов', 0.5186245552809781)],\n",
       " 'разрешение вопроса': [('обсуждение вопроса', 0.9807323023820061),\n",
       "  ('историей вопроса', 0.8790489815848778),\n",
       "  ('актами вопроса', 0.870984195507897),\n",
       "  ('решении вопроса', 0.838838947300385),\n",
       "  ('разрешение вере', 0.8055867038305552),\n",
       "  ('изложение вопроса', 0.8003963391133424),\n",
       "  ('контексте вопроса', 0.75713387700819),\n",
       "  ('постановка вопроса', 0.7283893072731861),\n",
       "  ('анализе вопроса', 0.7278821543731434),\n",
       "  ('признак вопроса', 0.7197526696583064)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest(search(text1, domain(text1)), domain(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае предложение правильное и замен предложено не было."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stee/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest(search(text2, domain(text2)), domain(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь предложено достаточно много подходящих вариантов на замену стилистически неверного сочетания \"автор думает\". Выхвачено также сочетание \"пример продемонстрировал\", правильное в целом, но несколько нетипичное, т.к. чаще используется \"продемонстрировать на примере\". Для него предложено намного меньше замен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stee/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'автор думает': [('автор наталкивается', 0.7601508028266003),\n",
       "  ('автор придерживается', 0.6741979416716583),\n",
       "  ('автор апеллирует', 0.6601508028266003),\n",
       "  ('автор посвящает', 0.6601508028266003),\n",
       "  ('автор сосредоточивает', 0.6601508028266003),\n",
       "  ('автор стремился', 0.6601508028266003),\n",
       "  ('автор обращается', 0.6342321372046617),\n",
       "  ('автор публикует', 0.605920585319349),\n",
       "  ('автор утверждает', 0.5725450736964377),\n",
       "  ('автор выражает', 0.5659547808523554)],\n",
       " 'пример продемонстрировал': [('пример совместим', 0.5625742287685846),\n",
       "  ('пример подтверждает', 0.5083440112613357)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest(search(text3, domain(text3)), domain(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом можно видеть, что большинство неточностей возникают из-за несовершенств системы поиска неправильных сочетаний, над которой я и планирую работать дальше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
